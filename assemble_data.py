"""
Assembles data from a dataset JSON and scraped TXT files into a TSV file to be parsed into a singular dataset by the model.
This uses the data generated from scrape_data and a JSON downloaded from https://eightportions.com/datasets/Recipes/
"""
from typing import List, Tuple, Dict
from utils import clean_paragraphs

JSON_PATH = 'datafiles/dataset.json'
"""The path the dataset JSON is saved at."""
TSV_PATH = 'datafiles/dataset.tsv'
"""The path the TSV file will be generated to"""
EXAMPLES_PER_CLASS = 60_000
"""The amount of examples per class to save. There are 199,030 ingredients with 83,465 unique values and 69,458 
instructions with 61,580 unique values."""


def get_raw_json() -> str:
    """
    :return: The contents of the file found at the `JSON_PATH` set above
    """
    with open(JSON_PATH) as datafile:
        return datafile.read()


def get_json_dict() -> Dict[str, List[str]]:
    """
    :return: The object described by the dataset JSON. This will be a list of dictionaries, each containing
    properties of a recipe (calories, ingridients, protiens, etc.)l, which in turn lead to lists or values.
    """
    with open('datafiles/dataset.json', 'r') as datafile:
        return eval(datafile.read().replace('null', 'None'))


def get_manual_data() -> Tuple[List[str], List[str]]:
    """
    :return: a tuple of the instructions and ingredients found in the TXT files generated by scrape_data
    (see save and reset in that file).
    """
    with open('datafiles/ingredients.txt') as ingredient_file, \
            open('datafiles/instructions.txt', 'r') as instruction_file:
        return ingredient_file.readlines(), instruction_file.readlines()


def get_data_lists() -> Tuple[List[str], List[str]]:
    ingredients, instructions = get_manual_data()
    # Trim spaces, remove blank/spacefill lines, remove duplocates
    # Cleanup is the same as actual inouts go through. Removing duplicates helps to remove junk that slipped
    # through the scraping and allows the model to become more general
    ingredients, instructions = clean_paragraphs(ingredients), clean_paragraphs(instructions)
    ingredients, instructions = set(ingredients), set(instructions)
    recipes = get_json_dict()
    i = 0
    while len(instructions) < EXAMPLES_PER_CLASS or len(ingredients) < EXAMPLES_PER_CLASS:
        item = recipes[i]
        if item:  # JSON contains a few empty recipes for some reason. this check the item is not empty.
            if len(instructions) < EXAMPLES_PER_CLASS:
                instructions = instructions.union(clean_paragraphs(item['directions']))
            if len(ingredients) < EXAMPLES_PER_CLASS:
                ingredients = ingredients.union(clean_paragraphs(item['ingredients']))
            print(f'{len(ingredients)}/{EXAMPLES_PER_CLASS}, {len(instructions)}/{EXAMPLES_PER_CLASS}')
        i += 1

    return list(instructions)[:EXAMPLES_PER_CLASS], list(ingredients)[:EXAMPLES_PER_CLASS]


def save_to_tsv(instructions, ingredients):
    """
    Assembles lists of instruction, ingredient and irrelevant data into a single TSV file

    :param instructions: a list of instruction data
    :param ingredients: a list of ingredient data
    :param irrelevants: a list of irrelevant data (preferably one found on websites)
    """
    dataset = []


    # Combine between the lists, alternating
    for i in range(EXAMPLES_PER_CLASS):
        dataset.append([ingredients[i], '1,0'])
        dataset.append([instructions[i], '0,1'])

    # Write the TSV file
    with open('datafiles/dataset.tsv', 'w+') as f:
        for item in dataset:
            f.write(f"{item[0]}\t{item[1]}\n")


# Running script: generate the TSV from the data files.
if __name__ == '__main__':
    save_to_tsv(*get_data_lists())
